{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heterogeneous Ensembles\n",
    "The obvious way to produce an ensemble of diverse classifiers is to use different model types as the base estimators. \n",
    " 1. We assess the performance of a classifier ensemble with 6 different estimators, *k*-NN, Logisitc Regression, D-Tree, Artificial Neural Net, Support Vector Classifier and Naive Bayes. \n",
    " 2. We measure diversity using the plain disagreement measure.\n",
    " 3. We compare this with the performance of a Bagging ensemble with 6 members.  \n",
    " \n",
    " The evaluation is done with a single hold-out test.  \n",
    " The `plain_dis` and `get_consensus_prediction` functions are imported from `ensemble_functions.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_pd = pd.read_csv('HotelRevHelpfulness.csv')\n",
    "hotel_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_pd.pop('hotelId').values\n",
    "y = hotel_pd.pop('reviewHelpfulness').values\n",
    "X = hotel_pd.values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heterogenous Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from ensemble_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data needs to be scaled for most of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "ann = make_pipeline(scaler, MLPClassifier(solver='lbfgs'))\n",
    "lr = make_pipeline(scaler, LogisticRegression())\n",
    "kNN = make_pipeline(scaler, KNeighborsClassifier(n_neighbors=3))\n",
    "dtree = DecisionTreeClassifier(criterion='entropy')\n",
    "gnb = make_pipeline(scaler, GaussianNB())\n",
    "svc = make_pipeline(scaler, SVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate estimator predictions and store in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estims = {'k-NN':kNN, 'Tree':dtree, 'Naive Bayes': \n",
    "          gnb,'ANN': ann, 'Logistic': lr, 'SVC': svc}\n",
    "\n",
    "res_df = pd.DataFrame()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for est in estims.keys():\n",
    "    clf = estims[est].fit(X_train,y_train)\n",
    "    y_preds = clf.predict(X_test)\n",
    "    res_df[est]=y_preds\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to return a count of the entries in lists `l1` and `l2` that are not equal.  \n",
    "This is the *plain disagreement* measure to guantify ensemble diversity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('%4.3f' % (plain_dis(res_df['k-NN'],res_df['Tree'])))\n",
    "print('%4.3f' % (plain_dis(res_df['Naive Bayes'],res_df['Tree'])))\n",
    "print('%4.3f' % (plain_dis(res_df['Naive Bayes'],res_df['k-NN'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the plain disagreement scores for the 6 estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = estims.keys()\n",
    "N = len(models)\n",
    "plain_dis_arr = np.zeros((N,N))\n",
    "\n",
    "for i_ind,i in enumerate(models):\n",
    "    for j_ind,j in enumerate(models):\n",
    "        plain_dis_arr[i_ind,j_ind] = plain_dis(res_df[i],res_df[j])\n",
    "plain_dis_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_dis_arr.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heterogeneous Ensemble Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df['Actual'] = y_test\n",
    "res_df['Consensus'] = get_consensus_prediction(res_df,res_df.columns)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_acc = []\n",
    "for m in models:\n",
    "    acc = accuracy_score(res_df['Actual'],res_df[m])\n",
    "    model_acc.append(acc)\n",
    "    print(m, '%4.3f' % acc)\n",
    "    \n",
    "c_acc = accuracy_score(res_df['Actual'],res_df['Consensus'])\n",
    "model_acc.append(c_acc)\n",
    "print('Consensus %4.3f' % c_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "Ensembles based on Bagging. \n",
    "- 10 ensemble members are trained using bootstrap resampling\n",
    "\n",
    "We don't need to worry about scaling here because the base estimator is a tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_bag = BaggingClassifier(dtree, \n",
    "                            n_estimators = 6,\n",
    "                            max_samples = 1.0, # bootstrap resampling \n",
    "                            bootstrap = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 6 members of the bagging ensemble trained on bootstrap samples from `X_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_ests = tree_bag.fit(X_train,y_train).estimators_\n",
    "bag_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, est in enumerate(bag_ests):\n",
    "    y_preds = est.predict(X_test)\n",
    "    bag_df['Est '+ str(i+1)]=y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bag_df['Actual'] = y_test\n",
    "bag_df['Consensus'] = get_consensus_prediction(bag_df,bag_df.columns)\n",
    "bag_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = 6\n",
    "bag_names = []\n",
    "for i in range(N):\n",
    "    bag_names.append('Est '+ str(i+1))\n",
    "\n",
    "bag_dis_arr = np.zeros((N,N))\n",
    "\n",
    "for i_ind,i in enumerate(bag_names):\n",
    "    for j_ind,j in enumerate(bag_names):\n",
    "        bag_dis_arr[i_ind,j_ind] = plain_dis(bag_df[i],bag_df[j])\n",
    "bag_dis_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Max difference in Hetero Ensemble: %4.3f' % (plain_dis_arr.max()))\n",
    "print('Max difference in Bagged Ensemble: %4.3f' % (bag_dis_arr.max()))\n",
    "maxv = max(bag_dis_arr.max(),plain_dis_arr.max())\n",
    "print('Overall max is: %4.3f' % maxv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_est_acc =[]\n",
    "for i in range(6):\n",
    "    ms = 'Est '+ str(i+1)\n",
    "    acc = accuracy_score(bag_df['Actual'],bag_df[ms])\n",
    "    print(ms, acc)\n",
    "    bag_est_acc.append(acc)\n",
    "bag_acc = accuracy_score(bag_df['Actual'],bag_df['Consensus'])\n",
    "print('Consensus', bag_acc)\n",
    "bag_est_acc.append(bag_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting results\n",
    "We look at the accuracies and the disagreement (diversity) among the ensemble members.   \n",
    "We see that the diversity with bagging is just as good as with the heterogenous ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot colourmaps of the disagreement matrices.\n",
    "\n",
    "def do_colourmap (matrix, names, title = ' ', **kwargs):\n",
    "    if 'vmx' in kwargs:    # check that 'reps' is a keyword\n",
    "        vmax_val = kwargs['vmx']\n",
    "    else: vmax_val = matrix.max()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    im = ax.imshow(matrix, cmap = 'gray', vmax= vmax_val)\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(len(names)))\n",
    "    ax.set_yticks(np.arange(len(names)))\n",
    "    # ... and label them with the respective list entries\n",
    "    ax.set_xticklabels(names)\n",
    "    ax.set_yticklabels(names)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(names)):\n",
    "        for j in range(len(names)):\n",
    "            text = ax.text(j, i, round(matrix[i, j],2),\n",
    "                           ha=\"center\", va=\"center\", color=\"r\")\n",
    "    ax.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`maxv` is the largest value in both arrays so colourmaps match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = list(models)\n",
    "f = do_colourmap(plain_dis_arr, model_names, \n",
    "             title = 'Heterogeneous ensemble disagreement', vmx = maxv)\n",
    "f.savefig('HeteroCM.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bag_names), bag_dis_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = do_colourmap(bag_dis_arr, bag_names, \n",
    "             title = 'Bagging ensemble disagreement', vmx = maxv)\n",
    "f.savefig('BagCM.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_barchart(names, values, colours, title = ' ',\n",
    "                    y_lab='', x_lab = '' , ymax = 1):\n",
    "    y_pos = np.arange(len(names))\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    plt.bar(y_pos, values, align='center', color = colours, alpha=0.5)\n",
    "    plt.xticks(y_pos, names)\n",
    "    plt.ylabel(y_lab)\n",
    "    plt.xlabel(x_lab)\n",
    "    plt.title(title)\n",
    "    plt.ylim((0,ymax))\n",
    "    plt.grid(axis = 'y')\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_names = list(models)\n",
    "model_names.append('Ensemble')\n",
    "clrs = ('b','b','b','b','b','b','r')\n",
    "f = simple_barchart(model_names,model_acc,clrs, ymax = 0.8, title = 'Heterogenous ensemble accuracy',\n",
    "                y_lab = 'Accuracy', x_lab = 'Model')\n",
    "f.savefig('HeteroBars.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrs = ('b','b','b','b','b','b','r')\n",
    "f = simple_barchart(bag_names +['Ensemble'],bag_est_acc,clrs, ymax = 0.8,\n",
    "                title = 'Bagging ensemble accuracy',\n",
    "                y_lab = 'Accuracy', x_lab = 'Model')\n",
    "f.savefig('BagBars.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
